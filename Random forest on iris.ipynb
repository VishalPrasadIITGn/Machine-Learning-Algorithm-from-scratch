{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries and reading file\n",
    "import csv\n",
    "f=open(\"irisself.txt\",'r')\n",
    "reader = csv.reader(f)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import random\n",
    "df=pd.read_csv('irisself.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and testing data\n",
    "#input parameters: a in dataframe and percent of test data reuired\n",
    "def testing_training_set(a,percent):\n",
    "    number=((percent/100)*len(a)) #calculatinting number of testcases required\n",
    "    number=round(number)     #converting it into an integer#\n",
    "    \n",
    "    #getting index of dataframe\n",
    "    index=a.index.tolist()  \n",
    "    #getting random number of indexes\n",
    "    random_index=random.sample(index,number) \n",
    "    #removing indexes\n",
    "    training_data=a.drop(random_index)  \n",
    "    testing_data=a.loc[random_index]    #getting testing data\n",
    "    global feat   #creating global feat\n",
    "    feat=a.columns\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training data and testing data\n",
    "training_data,testing_data=testing_training_set(df,30) \n",
    "\n",
    "#converting data to numpy array for easy use\n",
    "data_np=training_data.values\n",
    "test_np=testing_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if entropy is zero\n",
    "def is_entropy_zero(a):\n",
    "        label_list=a[0:-1,-1]  #getting label column\n",
    "        unique_labels=set(label_list) #creating set, so that duplicate values are removed and we get unique values\n",
    "        if (len(unique_labels))>=2: #if number of unique labels is greater than 1, then entropy cannot be zero\n",
    "            return False #boolean outputs to be used directly\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_entropy_zero(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returning the label with maximum count\n",
    "#incase of a tie, it returns the first value\n",
    "\n",
    "\n",
    "#getting labels on the classified data\n",
    "def put_label(a):\n",
    "    labels=a[:,-1] #getting labels\n",
    "    unique_labels=list(set(labels)) #making it set for unique values and then makin it a list for easy access\n",
    "    count=np.zeros((((len(unique_labels))),), dtype=int) #creating empty arrays of zero integer\n",
    "    count=list(count)   #\n",
    "    #print(len(unique_labels))\n",
    "    \n",
    "#getting maxximum count of a label\n",
    "    for x in range(0,(len(unique_labels))):\n",
    "        #print(x)\n",
    "        for y in range(0,(len(a))):\n",
    "           if (unique_labels[x-1] == labels[y-1]):\n",
    "                count[x-1]=count[x-1]+1\n",
    "    #print(count)\n",
    "    maximum_count=max(count)\n",
    "    return_index=(count.index(maximum_count)) #getting index of label with maxm count\n",
    "    return_label=unique_labels[return_index]  \n",
    "    return return_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wheter a category is continuous or category wise\n",
    "def continuous_or_categorical_data(b):\n",
    "    all_c=b.columns #getting all columns\n",
    "    #print(all_c)\n",
    "    all_c_with_cont_data = b._get_numeric_data().columns #columns with numeric values\n",
    "    #print(all_c_with_cont_data)\n",
    "    \n",
    "    l=[]\n",
    "    for x in all_c:\n",
    "        if x in all_c_with_cont_data:\n",
    "            l.append(\"continuous\")\n",
    "        else:\n",
    "            l.append(\"category\")\n",
    "    l.pop()\n",
    "    #print(l)\n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global feat_category\n",
    "feat_category=continuous_or_categorical_data(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating possible boundaries for splitting of data\n",
    "def division_boundaries2(a):\n",
    "    divide = {}\n",
    "    c = len(a[0]) #no of columns\n",
    "    for z in range(1,c): #looping for all columns exxcept last one\n",
    "        y = a[:, z-1]\n",
    "        uni = np.unique(y)\n",
    "        divide[z-1]=uni\n",
    "    return divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#division_boundaries2(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diving data based on column number and value\n",
    "def divide_data(a,c,v):\n",
    "    sv=a[:,c] #getting vvalue of column\n",
    "    d=feat_category[c] #type of column values #category or #continuous\n",
    "    if d == \"continuous\":\n",
    "        yes = a[sv <= v]\n",
    "        no = a[sv > v]\n",
    "    elif d ==\"category\": \n",
    "        yes = a[sv == v]\n",
    "        no = a[sv != v]\n",
    "    return yes, no\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting entropy\n",
    "def get_ent(a):\n",
    "    labels=a[:,-1]\n",
    "    unique_labels=list(set(labels))\n",
    "    count=np.zeros((((len(unique_labels))),), dtype=int) #removed -1\n",
    "    count=list(count)\n",
    "    #print(len(unique_labels))\n",
    "    \n",
    "\n",
    "    for x in range(0,(len(unique_labels))):\n",
    "        #print(x)\n",
    "        for y in range(0,(len(a))):\n",
    "           if (unique_labels[x-1] == labels[y-1]):\n",
    "                count[x-1]=count[x-1]+1\n",
    "    #print(count)\n",
    "    y=sum(count)\n",
    "    count[:] = [x / y for x in count]\n",
    "    z=count\n",
    "    #print(count)\n",
    "    z1=np.log2(z)\n",
    "    #print(z1)\n",
    "    rez=(z*z1)\n",
    "    rez=-sum(rez)\n",
    "    #print(rez)\n",
    "    #rez=rez+z[i]\n",
    "    return rez\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weighted entropy\n",
    "#weighted E= p1*E1+p2*E2\n",
    "def total_entropy(d1,d2):\n",
    "    l1=len(d1)\n",
    "    l2=len(d2)\n",
    "    l=l1+l2\n",
    "    p1=len(d1)/l\n",
    "    p2=len(d2)/l\n",
    "    E1=p1*get_ent(d1)\n",
    "    E2=p2*get_ent(d2)\n",
    "    Etotal=(E1+E2)\n",
    "    return Etotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deciding the best division\n",
    "def optimal_division(d,s): #getting data  and possible divisions\n",
    "        E=10000  #setting very high values of initial entropy\n",
    "        for x in s: #\n",
    "            for y in s[x]:\n",
    "                d1,d2=divide_data(d,x,y) #dividing data\n",
    "                newE=total_entropy(d1,d2) #getting weighted entropy\n",
    "                #getting value and col for least entropy\n",
    "                if E > newE:  #if new entropy is less\n",
    "                    E=newE  #making it equal to new entropy\n",
    "                    \n",
    "                    val=y  #returning these values\n",
    "                    col=x\n",
    "        return col,val\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating final binary tree\n",
    "\n",
    "def create_binary_T(df):\n",
    "    \n",
    "    data = df           \n",
    "    #if entrop is zero, it is a leaf node\n",
    "    if (is_entropy_zero(data)) :\n",
    "        label = put_label(data)  #getting output label for this branch\n",
    "        return label\n",
    "\n",
    "    else:    \n",
    "        #creating new subtree\n",
    "        division_values = division_boundaries2(data) #possible_values of division\n",
    "        div_c, div_v = optimal_division(data, division_values) #column and values for best division of data\n",
    "        div_1, div_2 = divide_data(data, div_c, div_v) #divided data output\n",
    "        \n",
    "        #feature on which division is based\n",
    "        feature_name = feat[div_c]\n",
    "        \n",
    "        #creating key-value pair :\n",
    "        #feature name and feature value for division\n",
    "        \n",
    "        node = \"feature: {} ,valueupto: {} ,Label:\".format(feature_name, div_v)\n",
    "        #node = \"{} <= {}\".format(feature_name, div_v)\n",
    "        #recursion part\n",
    "        subnode_1 = create_binary_T(div_1) #creating further sub nodes untill data is completely classified\n",
    "        subnode_2 = create_binary_T(div_2)    #second branch is made, as data was not pure   \n",
    "        \n",
    "        #making sub node\n",
    "        sub_node = {node: []}\n",
    "        #inserting the new sub nodes at the end of the node\n",
    "        sub_node[node].insert(len(sub_node[node]),subnode_1) #left subnode\n",
    "        sub_node[node].insert(len(sub_node[node]),subnode_2)  #right subnode\n",
    "\n",
    "        \n",
    "        return sub_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature: PetalLength ,valueupto: 1.9 ,Label:': ['Iris-setosa', {'feature: PetalWidth ,valueupto: 1.7 ,Label:': [{'feature: PetalLength ,valueupto: 4.9 ,Label:': ['Iris-versicolor', {'feature: PetalWidth ,valueupto: 1.5 ,Label:': ['Iris-virginica', 'Iris-versicolor']}]}, {'feature: PetalLength ,valueupto: 4.8 ,Label:': [{'feature: SepalLength ,valueupto: 5.9 ,Label:': ['Iris-versicolor', 'Iris-virginica']}, 'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = create_binary_T(data_np)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing features randomly(upto 2 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_forest_data(a):\n",
    "    \n",
    "    t=np.zeros((105,3),dtype=object)\n",
    "    x=random.sample(range(0,4),3)\n",
    "    t[:,0]=a[:,x[0]]\n",
    "    t[:,1]=a[:,x[1]]\n",
    "    t[:,-1]=a[:,-1]\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_for_data=rand_forest_data(data_np)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting output from tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applying_tree(input_data,binary_T):\n",
    "    question = list(binary_T.keys())[0]\n",
    "    #print(question)\n",
    "    _,attribute,_,value,_ = question.split(\" \")\n",
    "    print(value,attribute,input_data[attribute])\n",
    "    if input_data[attribute] <= float(value) or str(input_data[attribute]) == value:\n",
    "        answer = binary_T[question][0]\n",
    "    else:\n",
    "        answer = binary_T[question][1]\n",
    "    \n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return applying_tree(input_data, residual_tree)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df,T):\n",
    "    df[\"net_result\"]=df.apply(applying_tree,args=(T,))\n",
    "    df[\"true\"] = df[\"net_result\"] == df[\"label\"]\n",
    "    \n",
    "    total_acc = df[\"true\"].mean()\n",
    "    \n",
    "    return total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SepalLength            5.1\n",
       "SepalWidth             3.5\n",
       "PetalLength            1.4\n",
       "PetalWidth             0.2\n",
       "label          Iris-setosa\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = training_data.iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9 PetalLength 1.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Iris-setosa'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = create_binary_T(data_np)\n",
    "applying_tree(example,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying random forest:\n",
    "### (choosing random datasets, random features, creating multiple trees,applying test data over all trees, storing     output for all trees for getting majority result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_forest(x_df):  #add testing data\n",
    "    x_np=x_df.values\n",
    "    l=[]\n",
    "    l2=[]\n",
    "    _,final_test_df=testing_training_set(x_df,30)\n",
    "    for i in range(1,5):\n",
    "        x1_df,x2_df=testing_training_set(x_df,30)\n",
    "        x1_np=x1_df.values\n",
    "        x2_np=x2_df.values\n",
    "        t=rand_forest_data(x1_np)\n",
    "        tree1=create_binary_T(t)\n",
    "        print(tree1)\n",
    "        #x2_df[\"output\"]=x2_df.apply(applying_tree,args=(tree1,),axis=1,raw=True)\n",
    "        #temp=x2_df.apply(applying_tree,args=(tree1,),axis=1,raw=True)\n",
    "        temp=final_test_df.apply(applying_tree,args=(tree1,),axis=1,raw=True)\n",
    "        \n",
    "        l.extend(temp)\n",
    "    l2.extend(x2_df.iloc[:,-1])\n",
    "    #put testing data to tree and get output\n",
    "    #keep appending output\n",
    "    #use reshape\n",
    "    #print(l)\n",
    "    ##print(l2)\n",
    "    #t=rand_forest_data(a)\n",
    "    #tree2=create_binary_T(t)\n",
    "    #t=rand_forest_data(a)\n",
    "    #tree3=create_binary_T(t)\n",
    "    return l,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def rand_forest2(a):  #add testing data\n",
    "#    \n",
    " #   t=rand_forest_data(a)\n",
    " #   tree1=create_binary_T(t)\n",
    " #   \n",
    " #   t=rand_forest_data(a)\n",
    " #   tree2=create_binary_T(t)\n",
    " ##   t=rand_forest_data(a)\n",
    "  #  tree3=create_binary_T(t)\n",
    "  #  return tree1,tree2,tree3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature: SepalLength ,valueupto: 0.6 ,Label:': ['Iris-setosa', {'feature: SepalLength ,valueupto: 1.6 ,Label:': [{'feature: SepalWidth ,valueupto: 4.9 ,Label:': ['Iris-versicolor', {'feature: SepalLength ,valueupto: 1.5 ,Label:': ['Iris-virginica', 'Iris-versicolor']}]}, {'feature: SepalWidth ,valueupto: 4.8 ,Label:': [{'feature: SepalLength ,valueupto: 1.7 ,Label:': ['Iris-virginica', 'Iris-virginica']}, 'Iris-virginica']}]}]}\n",
      "5.2\n",
      "5.2\n",
      "3.4\n",
      "5.2\n",
      "5.8\n",
      "5.8\n",
      "2.6\n",
      "5.8\n",
      "6.7\n",
      "6.7\n",
      "3.3\n",
      "6.7\n",
      "6.5\n",
      "6.5\n",
      "2.8\n",
      "6.5\n",
      "5.5\n",
      "5.5\n",
      "2.4\n",
      "5.5\n",
      "5.6\n",
      "5.6\n",
      "3.0\n",
      "5.6\n",
      "4.8\n",
      "4.8\n",
      "3.1\n",
      "4.8\n",
      "5.7\n",
      "5.7\n",
      "2.5\n",
      "5.7\n",
      "5.8\n",
      "5.8\n",
      "2.7\n",
      "5.8\n",
      "4.8\n",
      "4.8\n",
      "3.0\n",
      "4.8\n",
      "6.4\n",
      "6.4\n",
      "2.8\n",
      "6.4\n",
      "5.6\n",
      "5.6\n",
      "2.9\n",
      "5.6\n",
      "6.3\n",
      "6.3\n",
      "3.3\n",
      "6.3\n",
      "5.4\n",
      "5.4\n",
      "3.0\n",
      "5.4\n",
      "6.2\n",
      "6.2\n",
      "2.8\n",
      "6.2\n",
      "7.3\n",
      "7.3\n",
      "2.9\n",
      "7.3\n",
      "5.8\n",
      "5.8\n",
      "2.8\n",
      "5.8\n",
      "7.7\n",
      "7.7\n",
      "3.0\n",
      "7.7\n",
      "7.1\n",
      "7.1\n",
      "3.0\n",
      "7.1\n",
      "5.7\n",
      "5.7\n",
      "3.8\n",
      "5.7\n",
      "4.4\n",
      "4.4\n",
      "3.0\n",
      "4.4\n",
      "4.6\n",
      "4.6\n",
      "3.2\n",
      "4.6\n",
      "5.7\n",
      "5.7\n",
      "2.9\n",
      "5.7\n",
      "6.5\n",
      "6.5\n",
      "3.0\n",
      "6.5\n",
      "5.0\n",
      "5.0\n",
      "3.4\n",
      "5.0\n",
      "5.4\n",
      "5.4\n",
      "3.9\n",
      "5.4\n",
      "5.4\n",
      "5.4\n",
      "3.9\n",
      "5.4\n",
      "6.7\n",
      "6.7\n",
      "3.1\n",
      "6.7\n",
      "6.2\n",
      "6.2\n",
      "3.4\n",
      "6.2\n",
      "7.7\n",
      "7.7\n",
      "3.8\n",
      "7.7\n",
      "6.0\n",
      "6.0\n",
      "2.9\n",
      "6.0\n",
      "6.3\n",
      "6.3\n",
      "2.5\n",
      "6.3\n",
      "5.8\n",
      "5.8\n",
      "4.0\n",
      "5.8\n",
      "5.5\n",
      "5.5\n",
      "4.2\n",
      "5.5\n",
      "4.9\n",
      "4.9\n",
      "3.0\n",
      "4.9\n",
      "5.7\n",
      "5.7\n",
      "2.8\n",
      "5.7\n",
      "5.4\n",
      "5.4\n",
      "3.4\n",
      "5.4\n",
      "6.9\n",
      "6.9\n",
      "3.1\n",
      "6.9\n",
      "6.9\n",
      "6.9\n",
      "3.1\n",
      "6.9\n",
      "5.0\n",
      "5.0\n",
      "3.5\n",
      "5.0\n",
      "5.9\n",
      "5.9\n",
      "3.2\n",
      "5.9\n",
      "6.4\n",
      "6.4\n",
      "3.2\n",
      "6.4\n",
      "6.2\n",
      "6.2\n",
      "2.2\n",
      "6.2\n",
      "5.9\n",
      "5.9\n",
      "3.0\n",
      "5.9\n",
      "6.4\n",
      "6.4\n",
      "2.8\n",
      "6.4\n",
      "{'feature: SepalWidth ,valueupto: 1.9 ,Label:': ['Iris-setosa', {'feature: SepalWidth ,valueupto: 4.7 ,Label:': ['Iris-versicolor', {'feature: SepalWidth ,valueupto: 5.1 ,Label:': [{'feature: SepalWidth ,valueupto: 4.8 ,Label:': ['Iris-virginica', {'feature: SepalLength ,valueupto: 2.2 ,Label:': ['Iris-virginica', {'feature: SepalLength ,valueupto: 3.0 ,Label:': [{'feature: SepalLength ,valueupto: 2.5 ,Label:': ['Iris-virginica', {'feature: SepalWidth ,valueupto: 4.9 ,Label:': ['Iris-virginica', {'feature: SepalWidth ,valueupto: 5.0 ,Label:': ['Iris-versicolor', {'feature: SepalLength ,valueupto: 2.7 ,Label:': ['Iris-virginica', 'Iris-virginica']}]}]}]}, 'Iris-virginica']}]}]}, 'Iris-virginica']}]}]}\n",
      "3.4\n",
      "3.4\n",
      "2.6\n",
      "2.6\n",
      "3.3\n",
      "3.3\n",
      "2.8\n",
      "2.8\n",
      "2.4\n",
      "2.4\n",
      "3.0\n",
      "3.0\n",
      "3.1\n",
      "3.1\n",
      "2.5\n",
      "2.5\n",
      "2.7\n",
      "2.7\n",
      "3.0\n",
      "3.0\n",
      "2.8\n",
      "2.8\n",
      "2.9\n",
      "2.9\n",
      "3.3\n",
      "3.3\n",
      "3.0\n",
      "3.0\n",
      "2.8\n",
      "2.8\n",
      "2.9\n",
      "2.9\n",
      "2.8\n",
      "2.8\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "3.8\n",
      "3.8\n",
      "3.0\n",
      "3.0\n",
      "3.2\n",
      "3.2\n",
      "2.9\n",
      "2.9\n",
      "3.0\n",
      "3.0\n",
      "3.4\n",
      "3.4\n",
      "3.9\n",
      "3.9\n",
      "3.9\n",
      "3.9\n",
      "3.1\n",
      "3.1\n",
      "3.4\n",
      "3.4\n",
      "3.8\n",
      "3.8\n",
      "2.9\n",
      "2.9\n",
      "2.5\n",
      "2.5\n",
      "4.0\n",
      "4.0\n",
      "4.2\n",
      "4.2\n",
      "3.0\n",
      "3.0\n",
      "2.8\n",
      "2.8\n",
      "3.4\n",
      "3.4\n",
      "3.1\n",
      "3.1\n",
      "3.1\n",
      "3.1\n",
      "3.5\n",
      "3.5\n",
      "3.2\n",
      "3.2\n",
      "3.2\n",
      "3.2\n",
      "2.2\n",
      "2.2\n",
      "3.0\n",
      "3.0\n",
      "2.8\n",
      "2.8\n",
      "{'feature: SepalLength ,valueupto: 0.6 ,Label:': ['Iris-setosa', {'feature: SepalLength ,valueupto: 1.6 ,Label:': [{'feature: SepalWidth ,valueupto: 4.9 ,Label:': ['Iris-versicolor', 'Iris-virginica']}, 'Iris-virginica']}]}\n",
      "5.2\n",
      "5.2\n",
      "5.8\n",
      "5.8\n",
      "6.7\n",
      "6.7\n",
      "6.5\n",
      "6.5\n",
      "5.5\n",
      "5.5\n",
      "5.6\n",
      "5.6\n",
      "4.8\n",
      "4.8\n",
      "5.7\n",
      "5.7\n",
      "5.8\n",
      "5.8\n",
      "4.8\n",
      "4.8\n",
      "6.4\n",
      "6.4\n",
      "5.6\n",
      "5.6\n",
      "6.3\n",
      "6.3\n",
      "5.4\n",
      "5.4\n",
      "6.2\n",
      "6.2\n",
      "7.3\n",
      "7.3\n",
      "5.8\n",
      "5.8\n",
      "7.7\n",
      "7.7\n",
      "7.1\n",
      "7.1\n",
      "5.7\n",
      "5.7\n",
      "4.4\n",
      "4.4\n",
      "4.6\n",
      "4.6\n",
      "5.7\n",
      "5.7\n",
      "6.5\n",
      "6.5\n",
      "5.0\n",
      "5.0\n",
      "5.4\n",
      "5.4\n",
      "5.4\n",
      "5.4\n",
      "6.7\n",
      "6.7\n",
      "6.2\n",
      "6.2\n",
      "7.7\n",
      "7.7\n",
      "6.0\n",
      "6.0\n",
      "6.3\n",
      "6.3\n",
      "5.8\n",
      "5.8\n",
      "5.5\n",
      "5.5\n",
      "4.9\n",
      "4.9\n",
      "5.7\n",
      "5.7\n",
      "5.4\n",
      "5.4\n",
      "6.9\n",
      "6.9\n",
      "6.9\n",
      "6.9\n",
      "5.0\n",
      "5.0\n",
      "5.9\n",
      "5.9\n",
      "6.4\n",
      "6.4\n",
      "6.2\n",
      "6.2\n",
      "5.9\n",
      "5.9\n",
      "6.4\n",
      "6.4\n",
      "{'feature: SepalLength ,valueupto: 1.9 ,Label:': ['Iris-setosa', {'feature: SepalLength ,valueupto: 4.8 ,Label:': ['Iris-versicolor', {'feature: SepalWidth ,valueupto: 1.7 ,Label:': [{'feature: SepalLength ,valueupto: 4.9 ,Label:': ['Iris-versicolor', {'feature: SepalWidth ,valueupto: 1.5 ,Label:': ['Iris-virginica', 'Iris-versicolor']}]}, 'Iris-virginica']}]}]}\n",
      "5.2\n",
      "5.2\n",
      "3.4\n",
      "5.8\n",
      "5.8\n",
      "2.6\n",
      "6.7\n",
      "6.7\n",
      "3.3\n",
      "6.5\n",
      "6.5\n",
      "2.8\n",
      "5.5\n",
      "5.5\n",
      "2.4\n",
      "5.6\n",
      "5.6\n",
      "3.0\n",
      "4.8\n",
      "4.8\n",
      "5.7\n",
      "5.7\n",
      "2.5\n",
      "5.8\n",
      "5.8\n",
      "2.7\n",
      "4.8\n",
      "4.8\n",
      "6.4\n",
      "6.4\n",
      "2.8\n",
      "5.6\n",
      "5.6\n",
      "2.9\n",
      "6.3\n",
      "6.3\n",
      "3.3\n",
      "5.4\n",
      "5.4\n",
      "3.0\n",
      "6.2\n",
      "6.2\n",
      "2.8\n",
      "7.3\n",
      "7.3\n",
      "2.9\n",
      "5.8\n",
      "5.8\n",
      "2.8\n",
      "7.7\n",
      "7.7\n",
      "3.0\n",
      "7.1\n",
      "7.1\n",
      "3.0\n",
      "5.7\n",
      "5.7\n",
      "3.8\n",
      "4.4\n",
      "4.4\n",
      "4.6\n",
      "4.6\n",
      "5.7\n",
      "5.7\n",
      "2.9\n",
      "6.5\n",
      "6.5\n",
      "3.0\n",
      "5.0\n",
      "5.0\n",
      "3.4\n",
      "5.4\n",
      "5.4\n",
      "3.9\n",
      "5.4\n",
      "5.4\n",
      "3.9\n",
      "6.7\n",
      "6.7\n",
      "3.1\n",
      "6.2\n",
      "6.2\n",
      "3.4\n",
      "7.7\n",
      "7.7\n",
      "3.8\n",
      "6.0\n",
      "6.0\n",
      "2.9\n",
      "6.3\n",
      "6.3\n",
      "2.5\n",
      "5.8\n",
      "5.8\n",
      "4.0\n",
      "5.5\n",
      "5.5\n",
      "4.2\n",
      "4.9\n",
      "4.9\n",
      "3.0\n",
      "5.7\n",
      "5.7\n",
      "2.8\n",
      "5.4\n",
      "5.4\n",
      "3.4\n",
      "6.9\n",
      "6.9\n",
      "3.1\n",
      "6.9\n",
      "6.9\n",
      "3.1\n",
      "5.0\n",
      "5.0\n",
      "3.5\n",
      "5.9\n",
      "5.9\n",
      "3.2\n",
      "6.4\n",
      "6.4\n",
      "3.2\n",
      "6.2\n",
      "6.2\n",
      "2.2\n",
      "5.9\n",
      "5.9\n",
      "3.0\n",
      "6.4\n",
      "6.4\n",
      "2.8\n"
     ]
    }
   ],
   "source": [
    "#rand_forest(data_np,test_np)\n",
    "l1,l2=rand_forest(df)\n",
    "\n",
    "#l1=l1[:,-1]\n",
    "#l2=l2[:,-1]\n",
    "#count=0\n",
    "#for x in range(0,len(l1)):\n",
    " #   if l1[x] == l2[x]:\n",
    " #       count=count+1\n",
    "#accura=count/len(l1)\n",
    "#print(accura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_dash=np.reshape(l1,(45,4))\n",
    "indi=l1_dash.argmax(axis=1)\n",
    "#print(indi)\n",
    "#final=[None]*45\n",
    "#for x in range(1,len(indi)):\n",
    "#    final[x]=l1_dash[x,indi]\n",
    "#print(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting predicted output and actual output\n",
    "### calculating accuracy for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica']\n",
      "['Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica']\n",
      "0.3111111111111111\n"
     ]
    }
   ],
   "source": [
    "#print(len(l2))\n",
    "final_rand_output=[]\n",
    "final_rand_output2=[]\n",
    "for x in range(0,180,4):\n",
    "    temp2=l1[x:x+4]\n",
    "    i=np.argmax(temp2)\n",
    "    #print(temp2[i])\n",
    "    final_rand_output.insert(-1,temp2[i])\n",
    "#print(l2)\n",
    "print(final_rand_output)\n",
    "print(l2)\n",
    "count=0\n",
    "for x in range(0,len(final_rand_output)):\n",
    "    if final_rand_output[x]==l2[x]:\n",
    "        count=count+1\n",
    "print(count/len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented entire paragraph\n",
    "\n",
    "#tree = create_binary_T(data_np)\n",
    "#l1=[]\n",
    "#l2=training_data.iloc[:,-1]\n",
    "#testing_data[\"output\"]=testing_data.apply(applying_tree,args=(tree,),axis=1)\n",
    "#l1=testing_data.apply(applying_tree,args=(tree,),axis=1)\n",
    "#print(l1)\n",
    "#print(l2)\n",
    "#applying_tree(testing_data,tree)\n",
    "#accu = accuracy(testing_data, tree)\n",
    "#print(accu)\n",
    "#accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
