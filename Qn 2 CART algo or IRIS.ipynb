{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries and reading file\n",
    "import csv\n",
    "f=open(\"irisself.txt\",'r')\n",
    "reader = csv.reader(f)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import random\n",
    "df=pd.read_csv('irisself.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and testing data\n",
    "#input parameters: a in dataframe and percent of test data reuired\n",
    "def testing_training_set(a,percent):\n",
    "    number=((percent/100)*len(a)) #calculatinting number of testcases required\n",
    "    number=round(number)     #converting it into an integer#\n",
    "    \n",
    "    #getting index of dataframe\n",
    "    index=a.index.tolist()  \n",
    "    #getting random number of indexes\n",
    "    random_index=random.sample(index,number) \n",
    "    #removing indexes\n",
    "    training_data=a.drop(random_index)  \n",
    "    testing_data=a.loc[random_index]    #getting testing data\n",
    "    global feat   #creating global feat\n",
    "    feat=a.columns\n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training data and testing data\n",
    "training_data,testing_data=testing_training_set(df,20) \n",
    "\n",
    "#converting data to numpy array for easy use\n",
    "data_np=training_data.values\n",
    "test_np=testing_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if entropy is zero\n",
    "def is_entropy_zero(a):\n",
    "        label_list=a[0:-1,-1]  #getting label column\n",
    "        unique_labels=set(label_list) #creating set, so that duplicate values are removed and we get unique values\n",
    "        if (len(unique_labels))>=2: #if number of unique labels is greater than 1, then entropy cannot be zero\n",
    "            return False #boolean outputs to be used directly\n",
    "        else:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_entropy_zero(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returning the label with maximum count\n",
    "#incase of a tie, it returns the first value\n",
    "\n",
    "\n",
    "#getting labels on the classified data\n",
    "def put_label(a):\n",
    "    labels=a[:,-1] #getting labels\n",
    "    unique_labels=list(set(labels)) #making it set for unique values and then makin it a list for easy access\n",
    "    count=np.zeros((((len(unique_labels))),), dtype=int) #creating empty arrays of zero integer\n",
    "    count=list(count)   #\n",
    "    #print(len(unique_labels))\n",
    "    \n",
    "#getting maxximum count of a label\n",
    "    for x in range(0,(len(unique_labels))):\n",
    "        #print(x)\n",
    "        for y in range(0,(len(a))):\n",
    "           if (unique_labels[x-1] == labels[y-1]):\n",
    "                count[x-1]=count[x-1]+1\n",
    "    #print(count)\n",
    "    maximum_count=max(count)\n",
    "    return_index=(count.index(maximum_count)) #getting index of label with maxm count\n",
    "    return_label=unique_labels[return_index]  \n",
    "    return return_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wheter a category is continuous or category wise\n",
    "def continuous_or_categorical_data(b):\n",
    "    all_c=b.columns #getting all columns\n",
    "    #print(all_c)\n",
    "    all_c_with_cont_data = b._get_numeric_data().columns #columns with numeric values\n",
    "    #print(all_c_with_cont_data)\n",
    "    \n",
    "    l=[]\n",
    "    for x in all_c:\n",
    "        if x in all_c_with_cont_data:\n",
    "            l.append(\"continuous\")\n",
    "        else:\n",
    "            l.append(\"category\")\n",
    "    l.pop()\n",
    "    #print(l)\n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global feat_category\n",
    "feat_category=continuous_or_categorical_data(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating possible boundaries for splitting of data\n",
    "def division_boundaries2(a):\n",
    "    divide = {}\n",
    "    c = len(a[0]) #no of columns\n",
    "    for z in range(1,c): #looping for all columns exxcept last one\n",
    "        y = a[:, z-1]\n",
    "        uni = np.unique(y)\n",
    "        divide[z-1]=uni\n",
    "    return divide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([4.3, 4.4, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.4, 5.5, 5.6, 5.7,\n",
       "        5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8, 6.9, 7.0,\n",
       "        7.1, 7.2, 7.3, 7.4, 7.7, 7.9], dtype=object),\n",
       " 1: array([2.0, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3,\n",
       "        3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.1, 4.2], dtype=object),\n",
       " 2: array([1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.9, 3.0, 3.3, 3.5, 3.6, 3.7,\n",
       "        3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0,\n",
       "        5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.3, 6.4,\n",
       "        6.7, 6.9], dtype=object),\n",
       " 3: array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6,\n",
       "        1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5], dtype=object)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "division_boundaries2(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diving data based on column number and value\n",
    "def divide_data(a,c,v):\n",
    "    sv=a[:,c] #getting vvalue of column\n",
    "    d=feat_category[c] #type of column values #category or #continuous\n",
    "    if d == \"continuous\":\n",
    "        yes = a[sv <= v]\n",
    "        no = a[sv > v]\n",
    "    elif d ==\"category\": \n",
    "        yes = a[sv == v]\n",
    "        no = a[sv != v]\n",
    "    return yes, no\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting entropy\n",
    "def get_ent(a):\n",
    "    labels=a[:,-1]\n",
    "    unique_labels=list(set(labels))\n",
    "    count=np.zeros((((len(unique_labels))),), dtype=int) #removed -1\n",
    "    count=list(count)\n",
    "    #print(len(unique_labels))\n",
    "    \n",
    "\n",
    "    for x in range(0,(len(unique_labels))):\n",
    "        #print(x)\n",
    "        for y in range(0,(len(a))):\n",
    "           if (unique_labels[x-1] == labels[y-1]):\n",
    "                count[x-1]=count[x-1]+1\n",
    "    #print(count)\n",
    "    y=sum(count)\n",
    "    count[:] = [x / y for x in count]\n",
    "    z=count\n",
    "    #print(count)\n",
    "    z1=np.log2(z)\n",
    "    #print(z1)\n",
    "    rez=(z*z1)\n",
    "    rez=-sum(rez)\n",
    "    #print(rez)\n",
    "    #rez=rez+z[i]\n",
    "    return rez\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weighted entropy\n",
    "#weighted E= p1*E1+p2*E2\n",
    "def total_entropy(d1,d2):\n",
    "    l1=len(d1)\n",
    "    l2=len(d2)\n",
    "    l=l1+l2\n",
    "    p1=len(d1)/l\n",
    "    p2=len(d2)/l\n",
    "    E1=p1*get_ent(d1)\n",
    "    E2=p2*get_ent(d2)\n",
    "    Etotal=(E1+E2)\n",
    "    return Etotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deciding the best division\n",
    "def optimal_division(d,s): #getting data  and possible divisions\n",
    "        E=10000  #setting very high values of initial entropy\n",
    "        for x in s: #\n",
    "            for y in s[x]:\n",
    "                d1,d2=divide_data(d,x,y) #dividing data\n",
    "                newE=total_entropy(d1,d2) #getting weighted entropy\n",
    "                #getting value and col for least entropy\n",
    "                if E > newE:  #if new entropy is less\n",
    "                    E=newE  #making it equal to new entropy\n",
    "                    \n",
    "                    val=y  #returning these values\n",
    "                    col=x\n",
    "        return col,val\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating final binary tree\n",
    "\n",
    "def create_binary_T(df):\n",
    "    \n",
    "    data = df           \n",
    "    #if entrop is zero, it is a leaf node\n",
    "    if (is_entropy_zero(data)) :\n",
    "        label = put_label(data)  #getting output label for this branch\n",
    "        return label\n",
    "\n",
    "    else:    \n",
    "        #creating new subtree\n",
    "        division_values = division_boundaries2(data) #possible_values of division\n",
    "        div_c, div_v = optimal_division(data, division_values) #column and values for best division of data\n",
    "        div_1, div_2 = divide_data(data, div_c, div_v) #divided data output\n",
    "        \n",
    "        #feature on which division is based\n",
    "        feature_name = feat[div_c]\n",
    "        \n",
    "        #creating key-value pair :\n",
    "        #feature name and feature value for division\n",
    "        node = \"feature: {} ,value upto: {} , Label:\".format(feature_name, div_v)\n",
    "        #recursion part\n",
    "        subnode_1 = create_binary_T(div_1) #creating further sub nodes untill data is completely classified\n",
    "        subnode_2 = create_binary_T(div_2)    #second branch is made, as data was not pure   \n",
    "        \n",
    "        #making sub node\n",
    "        sub_node = {node: []}\n",
    "        #inserting the new sub nodes at the end of the node\n",
    "        sub_node[node].insert(len(sub_node[node]),subnode_1) #left subnode\n",
    "        sub_node[node].insert(len(sub_node[node]),subnode_2)  #right subnode\n",
    "\n",
    "        \n",
    "        return sub_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature: PetalLength ,value upto: 1.9 , Label:': ['Iris-setosa', {'feature: PetalWidth ,value upto: 1.7 , Label:': [{'feature: PetalLength ,value upto: 4.9 , Label:': ['Iris-versicolor', {'feature: PetalWidth ,value upto: 1.6 , Label:': ['Iris-virginica', 'Iris-versicolor']}]}, {'feature: PetalLength ,value upto: 4.8 , Label:': [{'feature: SepalLength ,value upto: 5.9 , Label:': ['Iris-versicolor', 'Iris-virginica']}, 'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = create_binary_T(data_np)\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
